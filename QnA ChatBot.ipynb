{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fc6cd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7460d309",
   "metadata": {},
   "source": [
    "### Global variables to store generated question and answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2f28d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_question = \"\"\n",
    "generated_answer = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75f796e",
   "metadata": {},
   "source": [
    "### Function to submit answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b42512db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_answer():\n",
    "    global generated_question, generated_answer\n",
    "    user_answer_text = user_answer.get()\n",
    "    \n",
    "    if generated_answer is not None and user_answer_text.lower() == generated_answer.lower():\n",
    "        feedback = \"Correct!\"\n",
    "        # If the user's answer matches the generated answer, provide feedback directly\n",
    "        result_label.config(text=feedback) \n",
    "    else:\n",
    "        # If the user's answer is wrong, check with the LLM model again\n",
    "        api_key = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyX2lkIjoiMTA0N2IxNTctNmRlYy00NWM4LWEyNmItMzFmMDEwNTMyNzM5IiwidHlwZSI6ImFwaV90b2tlbiJ9.5BcSWLEOHTpMi-c5N8AtR_Q09ZMd_b9_oNmEZkIkao8\"\n",
    "        headers = {\"Authorization\": f\"Bearer {api_key}\"}\n",
    "        url = \"https://api.edenai.run/v2/text/chat\"\n",
    "        payload = {\n",
    "            \"text\": f\"Is '{user_answer_text}' the correct answer for '{generated_question}'?, If partially yes then how much percent and if no provide correct answer with explaination of one line only\",\n",
    "            \"providers\": [\"openai\"],\n",
    "            \"models\": [\"text-davinci-002\"],\n",
    "            \"temperature\": 0.9,\n",
    "            \"max_tokens\": 50,\n",
    "            \"n\": 1,\n",
    "            \"previous_history\": [] \n",
    "        }\n",
    "\n",
    "        try:\n",
    "            response = requests.post(url, json=payload, headers=headers)\n",
    "            response.raise_for_status()  \n",
    "            result = json.loads(response.text)\n",
    "            generated_text = result.get(\"openai\", {}).get(\"generated_text\", \"\").strip()\n",
    "\n",
    "            # Extract the assistant's message\n",
    "            assistant_message = result.get(\"openai\", {}).get(\"message\", [])\n",
    "            if assistant_message:\n",
    "                assistant_response = assistant_message[-1].get(\"message\", \"\")\n",
    "                result_label.config(text=assistant_response)\n",
    "            else:\n",
    "                result_label.config(text=\"Failed to get response.\")\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error making API request: {e}\")\n",
    "            result_label.config(text=\"Failed to check answer.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5da6258",
   "metadata": {},
   "source": [
    "### Function to generate a question based on the selected topic using the LLM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df8ccdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_question(*args):\n",
    "    global generated_question, generated_answer\n",
    "    topic = selected_topic.get()\n",
    "    api_key = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyX2lkIjoiMTA0N2IxNTctNmRlYy00NWM4LWEyNmItMzFmMDEwNTMyNzM5IiwidHlwZSI6ImFwaV90b2tlbiJ9.5BcSWLEOHTpMi-c5N8AtR_Q09ZMd_b9_oNmEZkIkao8\"\n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\"}\n",
    "    url = \"https://api.edenai.run/v2/text/chat\"\n",
    "    payload = {\n",
    "        \"text\": f\"Generate a very basic question with one word answer only related to {topic}.\",\n",
    "        \"providers\": [\"openai\"],\n",
    "        \"models\": [\"text-davinci-002\"],\n",
    "        \"temperature\": 0.9,\n",
    "        \"max_tokens\": 50,\n",
    "        \"n\": 1,\n",
    "        \"previous_history\": [] \n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, json=payload, headers=headers)\n",
    "        response.raise_for_status()  \n",
    "        result = json.loads(response.text)\n",
    "        generated_text = result.get(\"openai\", {}).get(\"generated_text\", \"\").strip()\n",
    "\n",
    "        # Extract the question and answer\n",
    "        question_parts = generated_text.split(\"?\")\n",
    "        if len(question_parts) > 1:\n",
    "            generated_question = question_parts[0].strip() + \"?\"  \n",
    "            generated_answer = question_parts[-1].strip().split(\":\")[-1].strip(\".!\").strip()\n",
    "        else:\n",
    "            generated_question = \"Failed to generate question.\"\n",
    "\n",
    "        # Clear other fields\n",
    "        question_text.config(state=\"normal\")\n",
    "        question_text.delete(\"1.0\", tk.END)\n",
    "        question_text.insert(tk.END, generated_question)\n",
    "        question_text.config(state=\"disabled\")\n",
    "        user_answer.delete(0, tk.END)\n",
    "        result_label.config(text=\"\")\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error making API request: {e}\")\n",
    "        question_text.config(state=\"normal\")\n",
    "        question_text.delete(\"1.0\", tk.END)\n",
    "        question_text.insert(tk.END, \"Failed to generate question.\")\n",
    "        question_text.config(state=\"disabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a65251a",
   "metadata": {},
   "source": [
    "### Web UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c25bd5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = tk.Tk()\n",
    "window.title(\"Generative AI Q&A\")\n",
    "window.configure(bg=\"#f0f0f0\")\n",
    "window.geometry(\"400x350\")\n",
    "\n",
    "# Label and dropdown for topic selection\n",
    "topic_label = tk.Label(window, text=\"Select Topic:\", bg=\"#f0f0f0\", font=(\"Arial\", 12))\n",
    "topic_label.pack(pady=(10,5))\n",
    "\n",
    "topics = [\"Geography\", \"Health\", \"Sports\"]\n",
    "selected_topic = tk.StringVar()\n",
    "selected_topic.set(topics[0])  # Set default value\n",
    "topic_dropdown = ttk.Combobox(window, textvariable=selected_topic, values=topics, state=\"readonly\")\n",
    "topic_dropdown.pack()\n",
    "topic_dropdown.bind(\"<<ComboboxSelected>>\", generate_question)\n",
    "\n",
    "# Label and text box for question display\n",
    "question_label = tk.Label(window, text=\"Generated Question:\", bg=\"#f0f0f0\", font=(\"Arial\", 12))\n",
    "question_label.pack(pady=(10,5))\n",
    "\n",
    "question_text = tk.Text(window, height=5, width=50)\n",
    "question_text.config(state=\"disabled\", bg=\"white\", bd=2, relief=\"solid\")\n",
    "question_text.pack()\n",
    "\n",
    "# Label and entry field for user answer\n",
    "answer_label = tk.Label(window, text=\"Your Answer:\", bg=\"#f0f0f0\", font=(\"Arial\", 12))\n",
    "answer_label.pack(pady=(10,5))\n",
    "\n",
    "user_answer = tk.Entry(window, width=40, bd=2, relief=\"solid\")\n",
    "user_answer.pack()\n",
    "\n",
    "# Submit button\n",
    "submit_button = tk.Button(window, text=\"Submit\", command=submit_answer, bg=\"#4caf50\", fg=\"black\", font=(\"Arial\", 12), bd=0, padx=10, pady=5)\n",
    "submit_button.pack(pady=(10,0))\n",
    "\n",
    "# Label to display the result\n",
    "result_label = tk.Label(window, text=\"\", bg=\"#f0f0f0\", font=(\"Arial\", 12))\n",
    "result_label.pack(pady=(10,5))\n",
    "\n",
    "window.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
